# slides_script.md

## Story Outline（章立て：7項目）

1) **導入**: 高信頼ソフトウェアにおける仕様駆動開発の重要性と課題
2) **問題提起**: 自然言語仕様と実装の乖離問題
3) **既存手法の限界**: 差分テストの「意味的盲点」
4) **提案手法**: SpecAudit - 仕様チェックリスト駆動監査フレームワーク
5) **評価**: Ethereum Fusakaアップグレード監査コンテストでの検証
6) **結果と限界**: 戦略別寄与、誤検知原因分析、高・中重大度未検出の分析
7) **結論と今後**: 得られた知見と改善の方向性

---

## Slide-by-slide Script

### Slide 1: SpecAudit - 仕様チェックリスト駆動による多実装コンプライアンス監査
- On-slide (what to show):
  - タイトル: 「SpecAudit: 仕様チェックリスト駆動による多実装コンプライアンス監査」
  - サブタイトル: Specification-Checklist-Driven Auditing for Multi-Implementation Compliance
  - 著者名・所属
  - 発表日
  - 背景に仕様書とコードが繋がるイメージ（抽象的なライン図）
- Speaker script (what to say):
  本日は「SpecAudit」という、仕様チェックリスト駆動による多実装コンプライアンス監査フレームワークについて発表します。本研究では、自然言語で書かれた仕様と、それを実装した複数のコードベースの間の整合性を、大規模言語モデルを用いたエージェントで体系的に監査する手法を提案し、実際のセキュリティ監査コンテストで評価しました。
- Transition: まず、この研究の背景となる課題についてご説明します。
- **参照資料**: 論文 Abstract, Introduction (§1)
- **引用文献**: なし（タイトルスライド）

---

### Slide 2: 高信頼ソフトウェアでは仕様と実装の整合性確認が不可欠である
- On-slide (what to show):
  - 左側: 自然言語仕様の例（RFC、EIP、設計書のイメージ）
  - 右側: 複数実装のコードベース（異なる言語で書かれた複数クライアント）
  - 中央: 「整合性監査」を示す双方向矢印と「?」マーク
  - キーワード: 「MUST（必須）」「SHOULD（推奨）」「MAY（任意）」（RFC 2119の規範語）
- Speaker script (what to say):
  航空管制、医療機器、金融システム、そしてブロックチェーンなど、高信頼性が求められるソフトウェアでは、仕様と実装の整合性確認が極めて重要です。これらのシステムでは、RFCや技術仕様書といった自然言語で記述された仕様があり、「MUST（必須）」「SHOULD（推奨）」といった規範語で要件が定義されています。しかし、これらの仕様を実装に正しく反映できているかを確認する作業は、現在も多くが人手に依存しており、時間がかかり、エラーが入りやすいという問題があります。
- Transition: 特に、複数のチームが同じ仕様を独立に実装する環境では、さらに複雑な問題が生じます。
- **参照資料**: research_notes.md §1.2（背景と動機）
- **引用文献**:
  - Liu et al., "AUTOSPEC: Synthesizing Precise Protocol Specs from Natural Language" arXiv:2511.17977, 2025 [6]
  - RFC 2119（規範語の定義）

---

### Slide 3: 多実装環境では「全員が同じ誤解をする」問題が発生する
- On-slide (what to show):
  - 上部: 1つの仕様文書（曖昧な記述を含む）
  - 下部: 複数の実装チーム（A, B, C, D...）が同じ方向に矢印で繋がる
  - 全実装が同じ「誤った解釈」に到達している図解
  - 引用テキスト: 「独立実装でも共通障害は偶然より有意に多く発生する」
- Speaker script (what to say):
  多実装環境、つまり同じ仕様を複数のチームが独立に実装する環境では、興味深い問題が生じます。1986年のKnightとLevesonの有名な研究で示されたように、独立に開発された実装であっても、仕様の曖昧な部分について同じ誤解をする「共通モード障害」が偶然より高い頻度で発生します。これは、仕様文書の曖昧さや、暗黙の前提が原因です。Nバージョンプログラミングでは「独立開発なら障害も独立」と仮定しますが、実際にはそうならないことが実証されています。
- Transition: この問題に対して、既存の自動化手法はどのように対処してきたでしょうか。
- **参照資料**: research_notes.md §1.3（Gap: G1）、論文 §1 Introduction
- **引用文献**:
  - Knight & Leveson, "An Experimental Evaluation of the Assumption of Independence in Multiversion Programming" IEEE TSE, 1986 [4]

---

### Slide 4: 差分テストは「全実装が同じ誤りをする」と検知できない
- On-slide (what to show):
  - 差分テスト/差分ファジングの概念図（複数実装に同じ入力、出力を比較）
  - 「挙動が一致」→「バグ検知不可」のフロー
  - 赤字で「意味的盲点（Semantic Blind Spot）」
  - 代表的手法の名前と発表年
- Speaker script (what to say):
  既存の自動化手法として、差分テストや差分ファジングがあります。Fluffy（2021年）やLOKI（2023年）といった手法は、複数の実装に同じ入力を与え、出力の「差分」を検知することでバグを発見します。これは非常に強力な手法ですが、構造的な限界があります。それは、すべての実装が同じ誤解をしている場合、差分が出ないためバグを検知できないという点です。我々はこれを「意味的盲点」と呼んでいます。差分テストのオラクル、つまり正解の判定基準は「他の実装との違い」であり、「仕様との整合性」ではないのです。
- Transition: この盲点を突破するには、「差分」ではなく「仕様そのもの」を根拠にした監査が必要です。
- **参照資料**: research_notes.md §1.3（Gap: G2）、論文 §2.1
- **引用文献**:
  - Yang et al., "Fluffy: Finding Consensus Bugs in Ethereum via Multi-Transaction Differential Fuzzing" OSDI, 2021 [1]
  - Ma et al., "LOKI: State-Aware Fuzzing Framework for the Implementation of Blockchain Consensus Protocols" NDSS, 2023 [2]
  - Kim et al., "FORKY: Fork State-Aware Differential Fuzzing for Blockchain Consensus Implementations" ICSE, 2025 [3]

---

### Slide 5: 仕様チェックリストは差分に依存しない監査の根拠となる
- On-slide (what to show):
  - 中央: 「仕様チェックリスト」（チェック項目のリスト）
  - 左矢印: 仕様文書から抽出
  - 右矢印: 各実装に対して独立に適用
  - 「差分ではなく、仕様を根拠に正しさを判定」というメッセージ
  - 「1つの発見 → 多実装へ横展開」の図解
- Speaker script (what to say):
  本研究の核心的なアイデアは、仕様からチェックリストを抽出し、それを各実装に独立に適用することです。これにより、実装間の差分ではなく、仕様そのものを正しさの根拠とできます。さらに重要なのは、ある実装で発見したバグパターンを、同じチェックリストを用いて他の実装にも横展開できる点です。これにより、1つの発見を多実装環境全体に効率的にスケールできます。我々はこれを「仕様チェックリスト駆動監査」と呼んでいます。
- Transition: この考え方を具体化したフレームワークがSpecAuditです。
- **参照資料**: research_notes.md §2.1（核心）、論文 §1 Introduction（キーインサイト）
- **引用文献**: なし（本研究の独自概念）

---

### Slide 6: SpecAuditは2フェーズ・3戦略で仕様準拠を体系的に監査する
- On-slide (what to show):
  - アーキテクチャ図（2段構成）
    - フェーズ1: 知識構造化（仕様抽出 → 実装マッピング → パターンデータベース）
    - フェーズ2: 体系的監査（戦略A/B/C）
  - 出力: 監査レポート（証跡付き）
  - 各フェーズをボックスで表現し、矢印でフローを示す
- Speaker script (what to say):
  SpecAuditは2つのフェーズで構成されます。フェーズ1は知識構造化で、自然言語仕様から規範要件を抽出し、それをコードにマッピングし、既知の脆弱性パターンをデータベース化します。フェーズ2は体系的監査で、3つの戦略を適用します。各戦略については次のスライドで詳しく説明します。最終的に、証跡付きの監査レポートを生成し、人間による検証を支援します。重要なのは、監査を再現可能な工程と成果物として固定している点です。
- Transition: 3つの監査戦略について詳しく見ていきましょう。
- **参照資料**: 論文 §3.1 Overview、§3.3-3.4、Figure 1
- **引用文献**: なし（本研究の手法）
- **図表**: Figure 1（アーキテクチャ図）を参照・再構成

---

### Slide 7: 戦略Bは1つの発見を多実装に横展開しスケールさせる
- On-slide (what to show):
  - 3戦略の比較表:
    - 戦略A: 仕様ベース静的監査（単一実装の直接チェック）
    - 戦略B: 横展開チェック（クロス実装チェック）← 強調
    - 戦略C: 動的テスト生成
  - 戦略Bの図解: クライアントAで発見 → クライアントB, C, D... へ展開
  - 具体例: 「範囲チェック欠落」をクライアントA→B, Cへ横展開
- Speaker script (what to say):
  3つの戦略のうち、特に重要なのが戦略B、横展開チェックです。これは、ある実装で発見したバグパターンを抽象化し、同じチェックリスト項目を他のすべての実装に対して検証する戦略です。例えば、クライアントAで「範囲チェックの欠落」を発見した場合、同じチェック項目をクライアントB、C、Dにも適用します。多実装環境では、仕様の曖昧な部分で複数チームが同じ誤解をしている可能性が高いため、この横展開が非常に効果的です。戦略Aは単一実装を仕様に照らして直接チェックし、戦略Cは動的テストを生成します。
- Transition: この手法を実際のセキュリティ監査コンテストで評価しました。
- **参照資料**: 論文 §3.4（Phase 2: Systematic Auditing）、Table 1
- **引用文献**: なし（本研究の手法）
- **図表**: Table 1（横展開チェックの具体例）を参照

---

### Slide 8: Ethereum Fusakaアップグレードの11クライアント監査で評価した
- On-slide (what to show):
  - 評価環境の概要表:
    - 対象: Ethereum Fusakaアップグレード（次期大型更新）
    - クライアント数: 11（合意層6 + 実行層5）
      - ※合意層: ブロック生成・検証を担当するノード群
      - ※実行層: トランザクション処理を担当するノード群
    - 全参加者: 366提出、101件有効 (27.6%)
    - 我々: 54提出、17件有効 (31.5%)
  - クライアント名リスト
    - 合意層: Nimbus, Lighthouse, Prysm, Teku, Lodestar, Grandine
    - 実行層: Geth, Reth, Erigon, Nethermind, Besu
- Speaker script (what to say):
  評価環境として、Ethereumの次期アップグレードであるFusakaの監査コンテストを使用しました。Ethereumでは、ブロックの生成や検証を担当する「合意層」と、実際のトランザクション処理を行う「実行層」に分かれており、それぞれ複数の独立したクライアント実装があります。今回は合意層6つ、実行層5つ、計11の本番クライアントが対象でした。全参加者合計で366件の提出があり、101件が有効と判定され、全体の有効率は27.6%でした。我々は54件を提出し、17件が有効と認められ、有効率31.5%で全体平均を上回りました。
- Transition: 最も重要な結果として、戦略別の寄与分析をご紹介します。
- **参照資料**: 論文 §4.2（Experimental Setup）、Table 2、contest-report-with-security-agent-v1.md §2
- **引用文献**: なし（評価環境の説明）
- **図表**: Table 2（コンテスト環境パラメータ）を参照

---

### Slide 9: 横展開チェックが有効発見の76.5%を占めた
- On-slide (what to show):
  - 円グラフ: 戦略別寄与
    - 横展開チェック: 76.5%
    - 仕様ベース静的監査: 17.6%
    - 動的テスト: 5.9%
  - 表形式でも併記:
    - 横展開チェック: 13件 (76.5%)
    - 仕様ベース静的監査: 3件 (17.6%)
    - 動的テスト: 1件 (5.9%)
  - 「1→N スケール」を強調するアイコン
- Speaker script (what to say):
  戦略別の寄与分析の結果、横展開チェック、つまり1つの発見を他の実装に展開する戦略が有効発見の76.5%、17件中13件を占めました。これは、多実装環境において、横展開戦略が極めて有効であることを示しています。仕様の曖昧な部分で複数チームが同じ誤解をしているという仮説と整合する結果です。仕様ベースの静的監査は3件、動的テストは1件のみで、5.9%にとどまりました。動的テストが少なかったのは、テスト環境の構築コストが高く、また差分テストと同様に意味的盲点の影響を受けるためです。
- Transition: 次に、誤検知の原因分析を見ていきます。
- **参照資料**: 論文 §4.3（RQ1）、Table 3-4、contest-report-with-security-agent-v1.md §2.3
- **引用文献**: なし（本研究の結果）
- **図表**: Table 4（戦略別寄与）を図示

---

### Slide 10: 誤検知の最大原因は大規模言語モデルの能力ではなく脅威モデル不整合である
- On-slide (what to show):
  - 棒グラフ: 誤検知原因分布
    - 脅威モデル不整合: 21件 (56.8%) ← 最大、強調
    - 既知/重複: 8件 (21.6%)
    - 分析エラー: 5件 (13.5%)
    - スコープ外: 3件 (8.1%)
  - 具体例の対比:
    - 我々の前提: 「実行層を信頼しない」
    - コンテストルール: 「実行層は信頼コンポーネント」
- Speaker script (what to say):
  37件の誤検知を分析した結果、最大の原因は「脅威モデル不整合」で56.8%を占めました。脅威モデルとは、「誰が攻撃者になりうるか」「どこまでを信頼するか」という前提条件のことです。具体的には、我々のプロンプトでは実行層、つまりトランザクションを処理する部分を「信頼しない」と設定していましたが、コンテストのルールでは「信頼コンポーネント」として扱われていました。この前提条件のズレが21件の誤検知を生みました。重要な洞察は、誤検知の過半数が大規模言語モデルの推論能力の問題ではなく、前提条件の不整合に起因しているという点です。これは、工程として前提を明示化することで改善可能です。
- Transition: しかし、本手法には明確な限界もあります。
- **参照資料**: 論文 §4.4（RQ2）、Table 7、contest-report-with-security-agent-v1.md §6
- **引用文献**: なし（本研究の結果）
- **図表**: Table 7（誤検知原因分布）を図示

---

### Slide 11: 高・中重大度の脆弱性は検出できなかった
- On-slide (what to show):
  - 重大度別検出率の表:
    - 高（High）: 0/5 (0%)
    - 中（Medium）: 0/2 (0%)
    - 低（Low）: 1/8 (12.5%)
  - 見逃し原因の内訳（円グラフまたはバー）:
    - 複雑な状態遷移: 42.9%（3件）
    - 動的境界条件: 28.6%（2件）
    - 外部依存: 14.3%（1件）
    - 仕様ニュアンス: 14.3%（1件）
  - 赤字で「重要な限界」
- Speaker script (what to say):
  重要な限界として、高重大度5件、中重大度2件、計7件の重大な脆弱性をすべて見逃しました。見逃しの原因を分析すると、42.9%が「複雑な状態遷移」、つまり長い状態変化の連鎖の先にある問題でした。28.6%が「動的境界条件」、つまり実行時に初めて決まる境界値の問題でした。例えば、キャッシュの状態遷移に起因する脆弱性や、不正なトランザクションデータによる実行時エラーは、静的なチェックリスト監査では捕捉できません。これは本手法の根本的な限界であり、モデル検査やシンボリック実行、ファジングとの統合が必要な領域です。
- Transition: これらの結果から、手法の得意・不得意が明確になりました。
- **参照資料**: 論文 §4.5（RQ3）、Table 8-9、contest-report-with-security-agent-v1.md §5
- **引用文献**: なし（本研究の結果）
- **図表**: Table 8（重大度別検出率）、Table 9（見逃し原因分布）を図示

---

### Slide 12: 本手法は横展開に強く複雑な状態空間探索に弱い
- On-slide (what to show):
  - 2列構成:
    - 左列（緑）「得意」:
      - 規範要件（MUST/SHOULD）の直接検証
      - 多実装への横展開（1→N）
      - 証跡付き監査レポート生成
    - 右列（赤）「苦手」:
      - 複雑な状態遷移（深い状態到達性）
      - 動的境界条件（実行時決定）
      - 外部依存・仕様の微妙なニュアンス
  - 改善方向の矢印: モデル検査、ファジング、仕様形式化
- Speaker script (what to say):
  結果をまとめると、本手法は規範要件の直接検証と、発見の多実装への横展開に強みがあります。仕様から抽出したチェックリストにより、監査を再現可能な工程として固定でき、証跡も残せます。一方、複雑な状態遷移を伴う脆弱性や、実行時に決まる境界条件の検出は苦手です。これらの領域には、モデル検査、シンボリック実行、プロパティベーステストといった補完的な手法が必要です。手法の限界を認識した上で、適切な領域に適用することが重要です。
- Transition: 関連研究との比較で、本手法の位置づけを確認します。
- **参照資料**: research_notes.md §9（Discussion）、論文 §4.6
- **引用文献**: なし（本研究の考察）

---

### Slide 13: 本手法は仕様起点×多実装×脅威モデル形式化で差別化される
- On-slide (what to show):
  - ポジショニングマップ（2軸: 仕様起点 vs コード起点、単一実装 vs 多実装）
  - 比較対象:
    - RFCAudit: 仕様起点、単一実装
    - RepoAudit: コード起点、単一実装（検証器重視）
    - Fluffy/LOKI: コード起点、多実装（差分依存）
    - SpecAudit: 仕様起点、多実装（チェックリスト再利用）
  - 「脅威モデル形式化」を独自要素として強調
- Speaker script (what to say):
  関連研究と比較すると、RFCAuditは仕様起点ですが単一実装を対象としています。RepoAuditはコード起点で検証器による誤検知削減を重視します。FluffyやLOKIは多実装の差分を利用しますが、仕様への言及はありません。SpecAuditは、仕様起点で多実装に対応し、かつ脅威モデルを明示的に形式化する点で差別化されます。特に、誤検知の最大原因が脅威モデル不整合であるという知見に基づき、前提条件を工程として固定することを重視しています。
- Transition: 最後に、本研究の貢献と今後の展望をまとめます。
- **参照資料**: 論文 §2（Related Work）、§2.6（Positioning Summary）、research_notes.md §7
- **引用文献**:
  - Wei et al., "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications" arXiv:2506.00714, 2025 [5]
  - "RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing" arXiv:2501.18160, 2025 [8]
  - Yang et al., "Fluffy" OSDI, 2021 [1]
  - Ma et al., "LOKI" NDSS, 2023 [2]

---

### Slide 14: 仕様チェックリスト化と前提の形式化が監査をスケールさせる
- On-slide (what to show):
  - 3つの貢献（番号付きリスト）:
    1. 横展開チェックが有効発見の76.5%を占めた（13/17件）
    2. 誤検知の56.8%が脅威モデル不整合に起因（21/37件、改善可能）
    3. 高・中重大度未検出の原因は複雑状態遷移・動的境界（0/7件、限界）
  - 持ち帰りメッセージ: 「監査のボトルネックはモデルの賢さだけでなく、前提・境界・規範要件の固定にある」
  - 今後の方向: モデル検査との統合、プロパティベーステスト、仕様の形式化
- Speaker script (what to say):
  本研究の貢献をまとめます。第一に、多実装環境において、横展開チェックが有効発見の76.5%を占め、チェックリスト再利用による横展開の有効性を示しました。第二に、誤検知の56.8%が脅威モデル不整合に起因しており、大規模言語モデルの能力向上だけでなく、前提条件の形式化が重要であることを示しました。第三に、高・中重大度脆弱性の未検出という限界を正直に報告し、その原因を分析しました。監査のボトルネックは「モデルを賢くする」だけでなく、「前提・境界・規範要件を工程として固定する」ことにあると考えています。今後は、モデル検査やシンボリック実行との統合、脅威モデルの形式化の実証評価を進めていく予定です。
- Transition: 以上で発表を終わります。ご質問をお待ちしております。
- **参照資料**: 論文 §5（Conclusion）、research_notes.md §10
- **引用文献**: なし（まとめスライド）

---

### Slide 15: ご清聴ありがとうございました
- On-slide (what to show):
  - タイトル: 「ご清聴ありがとうございました」
  - 連絡先・所属
  - QRコード（論文/コードへのリンク、任意）
  - 主要数値の再掲（小さく）:
    - 横展開チェック: 76.5%
    - 誤検知・脅威モデル: 56.8%
    - 高・中重大度: 0%
- Speaker script (what to say):
  ご清聴ありがとうございました。SpecAuditは、仕様チェックリストを用いて多実装の整合性を監査するフレームワークです。実運用環境での評価により、横展開戦略の有効性と、脅威モデル形式化の重要性を示しました。ご質問やご意見をお待ちしております。
- Transition: （Q&Aへ）
- **参照資料**: なし
- **引用文献**: なし

---

## Backup Slides（4枚）

### Backup 1: 具体的な発見事例 - Nimbus カストディローテーション DoS
- On-slide:
  - 発見のフロー図:
    1. 仕様: 「カストディグループ数は NUMBER_OF_CUSTODY_GROUPS (128) を超えてはならない」
       ※カストディグループ: データ可用性サンプリングで各ノードが担当するデータ群
    2. マッピング: peerdas_helpers.nim
    3. 逸脱: ループ条件で検証なし（`while custody_groups.len < custody_group_count`）
  - コード断片（該当箇所をハイライト）
  - 結果: 低重大度として認定
- Speaker script:
  唯一の低重大度発見の具体例です。仕様から「カストディグループ数は128を超えてはならない」という要件を抽出しました。カストディグループとは、データ可用性サンプリングという技術で各ノードが担当するデータの集まりのことです。Nimbusの該当コードにマッピングした結果、この上限チェックがループ条件で行われておらず、悪意あるピアが過大な値を送ることでサービス拒否攻撃が可能でした。これは仕様駆動監査の成功例です。
- **参照資料**: contest-report-with-security-agent-v1.md §4.1、issue-15
- **引用文献**: なし

### Backup 2: V2改善 - 脅威モデル形式化による誤検知削減
- On-slide:
  - V1とV2の比較図:
    - V1: 脅威モデルが暗黙的（プロンプト内に散在）
    - V2: 脅威モデルを独立フェーズに（アクター、信頼レベル、境界エッジ）
  - V2成果物の例:
    - 8アクター、12境界エッジ
    - 信頼レベル: 信頼 / 半信頼 / 非信頼
  - 期待される効果: 脅威モデル不整合による誤検知の削減
- Speaker script:
  V1の分析に基づき、V2では脅威モデルを独立したフェーズとして形式化しました。アクターと信頼レベル、境界エッジを明示的に定義することで、監査前に前提条件を固定します。例えば、「実行層は信頼コンポーネントか否か」を事前に明示することで、V1で発生した56.8%の脅威モデル不整合を構造的に削減することを目指しています。V2は設計提案であり、実証評価は今後の課題です。
- **参照資料**: 論文 §3.6（V2）、research_notes.md §5
- **引用文献**: なし

### Backup 3: 見逃した高重大度脆弱性の詳細分析
- On-slide:
  - 5件の高重大度脆弱性リスト:
    - #40: プロポーザ計算エラー（仕様ニュアンス）
      ※プロポーザ: ブロックを提案するバリデータ
    - #190: Prysm キャッシュ問題（複雑状態遷移）
    - #203: c-kzg 弱いフィアット・シャミア変換（外部依存）
      ※フィアット・シャミア: 暗号学的証明で使われる技法
    - #176: Nethermind 不正ブロブトランザクション（動的境界）
      ※ブロブ: 大容量データを効率的に扱うための仕組み
    - #210: Nethermind ブロブハッシュ不一致（動的境界）
  - 各脆弱性の見逃し原因カテゴリを色分け
- Speaker script:
  見逃した5件の高重大度脆弱性を詳細に分析しました。#40はプロポーザ、つまりブロック提案者の計算における仕様の微妙なニュアンスの見落としでした。#190は複雑なキャッシュ状態遷移、#203は外部暗号ライブラリにおけるフィアット・シャミア変換の実装問題でした。#176と#210は、ブロブと呼ばれる大容量データ処理における実行時の動的境界条件に関わるものでした。これらは静的なチェックリスト監査の限界を示しており、異なるアプローチが必要な領域です。
- **参照資料**: contest-report-with-security-agent-v1.md §5.2、sherlock_contest_1140_statistics.md（高重大度Issues）
- **引用文献**: なし

### Backup 4: 評価環境の詳細 - Fusakaコンテストの重大度定義
- On-slide:
  - 重大度閾値の表:
    - 致命的（Critical）: ネットワークの50%超に影響
    - 高（High）: 33%超
    - 中（Medium）: 5%超
    - 低（Low）: 0.01%超
    - 情報提供（Informational）: クライアント側が修正価値を認めた場合のみ有効
  - 賞金プール: $2,000,000（うち情報提供プール: $25,000）
  - 「低・情報提供でも運用上の価値がある」というメッセージ
- Speaker script:
  Fusakaコンテストの重大度定義は非常に厳格で、高重大度はネットワークの33%以上に影響を与える脆弱性に限定されます。これはEthereumネットワーク全体の約3分の1のノードに影響するという意味で、極めて高いハードルです。このため、低重大度や情報提供レベルでも、実運用における事故回避や仕様準拠性の担保として十分な価値があります。我々の17件の有効発見のうち16件が情報提供レベルでしたが、これらはすべてクライアント開発チームが修正価値を認めたものです。
- **参照資料**: research_notes.md §4.5.1（Severity定義）、sherlock_contest_1140_statistics.md
- **引用文献**: なし

---

## 発表時間配分（目安）

| スライド | 内容 | 目安時間 |
|:--------|:-----|:--------|
| 1 | タイトル | 30秒 |
| 2 | 背景：仕様と実装の整合性 | 50秒 |
| 3 | 問題：共通誤解 | 50秒 |
| 4 | ギャップ：差分テストの限界 | 60秒 |
| 5 | キーアイデア：仕様チェックリスト | 50秒 |
| 6 | 提案：SpecAudit概要 | 50秒 |
| 7 | 戦略B：横展開チェック | 60秒 |
| 8 | 評価環境：Fusaka | 50秒 |
| 9 | 結果1：戦略別寄与 | 60秒 |
| 10 | 結果2：誤検知原因分析 | 60秒 |
| 11 | 結果3：限界分析 | 60秒 |
| 12 | 議論：得意・苦手 | 50秒 |
| 13 | 関連研究との位置づけ | 50秒 |
| 14 | 結論・貢献 | 60秒 |
| 15 | Thank you | 20秒 |
| **合計** | | **約14分** |

---

## 引用文献一覧（発表で言及するもの）

[1] S. Yang et al., "Finding Consensus Bugs in Ethereum via Multi-Transaction Differential Fuzzing (Fluffy)," OSDI, 2021.

[2] F. Ma et al., "LOKI: State-Aware Fuzzing Framework for the Implementation of Blockchain Consensus Protocols," NDSS, 2023.

[3] I. Kim et al., "Fork State-Aware Differential Fuzzing for Blockchain Consensus Implementations (FORKY)," ICSE, 2025.

[4] J. C. Knight and N. G. Leveson, "An Experimental Evaluation of the Assumption of Independence in Multiversion Programming," IEEE TSE, 1986.

[5] Z. Wei et al., "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications," arXiv:2506.00714, 2025.

[6] K. Liu et al., "Synthesizing Precise Protocol Specs from Natural Language for Effective Test Generation (AUTOSPEC)," arXiv:2511.17977, 2025.

[8] "RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing," arXiv:2501.18160, 2025.

---

## スライドデザインガイドライン

- **フォント**: BIZ UDPMincho（日本語）
- **背景**: 白
- **文字・図**: 黒基調（アクセントカラーは赤・緑を控えめに）
- **タイトル**: 各スライドは「主張の文章」をタイトルに（名詞句禁止）
- **本文**: 箇条書きは最小限、視覚的証拠（図・表・数値）中心
- **1スライド = 1メッセージ**: 要素は最大3つ
- **タイトル/Thank youスライド**: coverレイアウト
- **用語**: 英語は固有名詞を除き日本語/カタカナに統一、Ethereum専門用語は初出で説明を付記
