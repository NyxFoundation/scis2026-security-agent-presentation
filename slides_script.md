# slides_script.md

## Story Outline（章立て：7項目）

1) **導入**: 高信頼ソフトウェアにおける仕様駆動開発の重要性と課題
2) **問題提起**: 自然言語仕様と実装の乖離問題
3) **既存手法の限界**: 差分テストの「意味的盲点」
4) **提案手法**: SpecAudit - 仕様チェックリスト駆動監査フレームワーク
5) **評価**: Ethereum Fusakaアップグレード監査コンテストでの検証
6) **結果と限界**: 戦略別寄与、誤検知原因分析、高・中重大度未検出の分析
7) **結論と今後**: 得られた知見と改善の方向性

---

## Slide-by-slide Script

### Slide 1: SpecAudit - 仕様チェックリスト駆動による多実装コンプライアンス監査
- On-slide (what to show):
  - タイトル: 「SpecAudit: 仕様チェックリスト駆動による多実装コンプライアンス監査」
  - サブタイトル: Specification-Checklist-Driven Auditing for Multi-Implementation Compliance
  - 著者名・所属
  - 発表日
  - 背景に仕様書とコードが繋がるイメージ（抽象的なライン図）
- Speaker script (what to say):
  本日は「SpecAudit」という、仕様チェックリスト駆動による多実装コンプライアンス監査フレームワークについて発表します。本研究では、自然言語で書かれた仕様と、それを実装した複数のコードベースの間の整合性を、大規模言語モデルを用いたエージェントで体系的に監査する手法を提案し、実際のセキュリティ監査コンテストで評価しました。
- Transition: まず、この研究の背景となる課題についてご説明します。
- **参照資料**: 論文 Abstract, Introduction (§1)
- **引用文献**: なし（タイトルスライド）

---

### Slide 2: 高信頼ソフトウェアでは仕様と実装の整合性確認が不可欠である
- On-slide (what to show):
  - 左側: 自然言語仕様の例（RFC、EIP、設計書のイメージ）
  - 右側: 複数実装のコードベース（異なる言語で書かれた複数クライアント）
  - 中央: 「整合性監査」を示す双方向矢印と「?」マーク
  - キーワード: 「MUST（必須）」「SHOULD（推奨）」「MAY（任意）」（RFC 2119の規範語）
- Speaker script (what to say):
  航空管制、医療機器、金融システム、そしてブロックチェーンなど、高信頼性が求められるソフトウェアでは、仕様と実装の整合性確認が極めて重要です。これらのシステムでは、RFCや技術仕様書といった自然言語で記述された仕様があり、「MUST（必須）」「SHOULD（推奨）」といった規範語で要件が定義されています。しかし、これらの仕様を実装に正しく反映できているかを確認する作業は、現在も多くが人手に依存しており、時間がかかり、エラーが入りやすいという問題があります。
- Transition: 特に、複数のチームが同じ仕様を独立に実装する環境では、さらに複雑な問題が生じます。
- **参照資料**: research_notes.md §1.2（背景と動機）
- **引用文献**:
  - Liu et al., "AUTOSPEC: Synthesizing Precise Protocol Specs from Natural Language" arXiv:2511.17977, 2025 [6]
  - RFC 2119（規範語の定義）

---

### Slide 3: 多実装環境では「全員が同じ誤解をする」問題が発生する
- On-slide (what to show):
  - 上部: 1つの仕様文書（曖昧な記述を含む）
  - 下部: 複数の実装チーム（A, B, C, D...）が同じ方向に矢印で繋がる
  - 全実装が同じ「誤った解釈」に到達している図解
  - 引用テキスト: 「独立実装でも共通障害は偶然より有意に多く発生する」
- Speaker script (what to say):
  多実装環境、つまり同じ仕様を複数のチームが独立に実装する環境では、興味深い問題が生じます。1986年のKnightとLevesonの有名な研究で示されたように、独立に開発された実装であっても、仕様の曖昧な部分について同じ誤解をする「共通モード障害」が偶然より高い頻度で発生します。これは、仕様文書の曖昧さや、暗黙の前提が原因です。Nバージョンプログラミングでは「独立開発なら障害も独立」と仮定しますが、実際にはそうならないことが実証されています。
- Transition: この問題に対して、既存の自動化手法はどのように対処してきたでしょうか。
- **参照資料**: research_notes.md §1.3（Gap: G1）、論文 §1 Introduction
- **引用文献**:
  - Knight & Leveson, "An Experimental Evaluation of the Assumption of Independence in Multiversion Programming" IEEE TSE, 1986 [4]

---

### Slide 4: 差分テストは「全実装が同じ誤りをする」と検知できない
- On-slide (what to show):
  - 差分テスト/差分ファジングの概念図（複数実装に同じ入力、出力を比較）
  - 「挙動が一致」→「バグ検知不可」のフロー
  - 赤字で「意味的盲点（Semantic Blind Spot）」
  - 代表的手法の名前と発表年
- Speaker script (what to say):
  既存の自動化手法として、差分テストや差分ファジングがあります。Fluffy（2021年）やLOKI（2023年）といった手法は、複数の実装に同じ入力を与え、出力の「差分」を検知することでバグを発見します。これは非常に強力な手法ですが、構造的な限界があります。それは、すべての実装が同じ誤解をしている場合、差分が出ないためバグを検知できないという点です。我々はこれを「意味的盲点」と呼んでいます。差分テストのオラクル、つまり正解の判定基準は「他の実装との違い」であり、「仕様との整合性」ではないのです。
- Transition: この盲点を突破するには、「差分」ではなく「仕様そのもの」を根拠にした監査が必要です。
- **参照資料**: research_notes.md §1.3（Gap: G2）、論文 §2.1
- **引用文献**:
  - Yang et al., "Fluffy: Finding Consensus Bugs in Ethereum via Multi-Transaction Differential Fuzzing" OSDI, 2021 [1]
  - Ma et al., "LOKI: State-Aware Fuzzing Framework for the Implementation of Blockchain Consensus Protocols" NDSS, 2023 [2]
  - Kim et al., "FORKY: Fork State-Aware Differential Fuzzing for Blockchain Consensus Implementations" ICSE, 2025 [3]

---

### Slide 5: 仕様チェックリストは差分に依存しない監査の根拠となる
- On-slide (what to show):
  - 中央: 「仕様チェックリスト」（チェック項目のリスト）
  - 左矢印: 仕様文書から抽出
  - 右矢印: 各実装に対して独立に適用
  - 「差分ではなく、仕様を根拠に正しさを判定」というメッセージ
  - 「1つの発見 → 多実装へ横展開」の図解
- Speaker script (what to say):
  本研究の核心的なアイデアは、仕様からチェックリストを抽出し、それを各実装に独立に適用することです。これにより、実装間の差分ではなく、仕様そのものを正しさの根拠とできます。さらに重要なのは、ある実装で発見したバグパターンを、同じチェックリストを用いて他の実装にも横展開できる点です。これにより、1つの発見を多実装環境全体に効率的にスケールできます。我々はこれを「仕様チェックリスト駆動監査」と呼んでいます。
- Transition: この考え方を具体化したフレームワークがSpecAuditです。
- **参照資料**: research_notes.md §2.1（核心）、論文 §1 Introduction（キーインサイト）
- **引用文献**: なし（本研究の独自概念）

---

### Slide 6: SpecAuditは2フェーズ・3戦略で仕様準拠を体系的に監査する
- On-slide (what to show):
  - アーキテクチャ図（2段構成）
    - フェーズ1: 知識構造化（仕様抽出 → 実装マッピング → パターンデータベース）
    - フェーズ2: 体系的監査（戦略A/B/C）
  - 出力: 監査レポート（証跡付き）
  - 各フェーズをボックスで表現し、矢印でフローを示す
- Speaker script (what to say):
  SpecAuditは2つのフェーズで構成されます。フェーズ1は知識構造化で、自然言語仕様から規範要件を抽出し、それをコードにマッピングし、既知の脆弱性パターンをデータベース化します。フェーズ2は体系的監査で、3つの戦略を適用します。各戦略については次のスライドで詳しく説明します。最終的に、証跡付きの監査レポートを生成し、人間による検証を支援します。重要なのは、監査を再現可能な工程と成果物として固定している点です。
- Transition: 3つの監査戦略について詳しく見ていきましょう。
- **参照資料**: 論文 §3.1 Overview、§3.3-3.4、Figure 1
- **引用文献**: なし（本研究の手法）
- **図表**: Figure 1（アーキテクチャ図）を参照・再構成

---

### Slide 7: 戦略Bは1つの発見を多実装に横展開しスケールさせる
- On-slide (what to show):
  - 3戦略の比較表:
    - 戦略A: 仕様ベース静的監査（単一実装の直接チェック）
    - 戦略B: 横展開チェック（クロス実装チェック）← 強調
    - 戦略C: 動的テスト生成
  - 戦略Bの図解: クライアントAで発見 → クライアントB, C, D... へ展開
  - 具体例: 「範囲チェック欠落」をクライアントA→B, Cへ横展開
- Speaker script (what to say):
  3つの戦略のうち、特に重要なのが戦略B、横展開チェックです。これは、ある実装で発見したバグパターンを抽象化し、同じチェックリスト項目を他のすべての実装に対して検証する戦略です。例えば、クライアントAで「範囲チェックの欠落」を発見した場合、同じチェック項目をクライアントB、C、Dにも適用します。多実装環境では、仕様の曖昧な部分で複数チームが同じ誤解をしている可能性が高いため、この横展開が非常に効果的です。戦略Aは単一実装を仕様に照らして直接チェックし、戦略Cは動的テストを生成します。
- Transition: この手法を実際のセキュリティ監査コンテストで評価しました。
- **参照資料**: 論文 §3.4（Phase 2: Systematic Auditing）、Table 1
- **引用文献**: なし（本研究の手法）
- **図表**: Table 1（横展開チェックの具体例）を参照

---

### Slide 8: Ethereum Fusakaアップグレードの11クライアント監査で評価した
- On-slide (what to show):
  - 評価環境の概要表:
    - 対象: Ethereum Fusakaアップグレード（次期大型更新）
    - クライアント数: 11（合意層6 + 実行層5）
      - ※合意層: ブロック生成・検証を担当するノード群
      - ※実行層: トランザクション処理を担当するノード群
    - 全参加者: 366提出、101件有効 (27.6%)
    - 我々: 54提出、17件有効 (31.5%)
  - クライアント名リスト
    - 合意層: Nimbus, Lighthouse, Prysm, Teku, Lodestar, Grandine
    - 実行層: Geth, Reth, Erigon, Nethermind, Besu
- Speaker script (what to say):
  評価環境として、Ethereumの次期アップグレードであるFusakaの監査コンテストを使用しました。Ethereumでは、ブロックの生成や検証を担当する「合意層」と、実際のトランザクション処理を行う「実行層」に分かれており、それぞれ複数の独立したクライアント実装があります。今回は合意層6つ、実行層5つ、計11の本番クライアントが対象でした。全参加者合計で366件の提出があり、101件が有効と判定され、全体の有効率は27.6%でした。我々は54件を提出し、17件が有効と認められ、有効率31.5%で全体平均を上回りました。
- Transition: 最も重要な結果として、戦略別の寄与分析をご紹介します。
- **参照資料**: 論文 §4.2（Experimental Setup）、Table 2、contest-report-with-security-agent-v1.md §2
- **引用文献**: なし（評価環境の説明）
- **図表**: Table 2（コンテスト環境パラメータ）を参照

---

### Slide 9: 横展開チェックが有効発見の76.5%を占めた
- On-slide (what to show):
  - 円グラフ: 戦略別寄与
    - 横展開チェック: 76.5%
    - 仕様ベース静的監査: 17.6%
    - 動的テスト: 5.9%
  - 表形式でも併記:
    - 横展開チェック: 13件 (76.5%)
    - 仕様ベース静的監査: 3件 (17.6%)
    - 動的テスト: 1件 (5.9%)
  - 「1→N スケール」を強調するアイコン
- Speaker script (what to say):
  戦略別の寄与分析の結果、横展開チェック、つまり1つの発見を他の実装に展開する戦略が有効発見の76.5%、17件中13件を占めました。これは、多実装環境において、横展開戦略が極めて有効であることを示しています。仕様の曖昧な部分で複数チームが同じ誤解をしているという仮説と整合する結果です。仕様ベースの静的監査は3件、動的テストは1件のみで、5.9%にとどまりました。動的テストが少なかったのは、テスト環境の構築コストが高く、また差分テストと同様に意味的盲点の影響を受けるためです。
- Transition: 次に、誤検知の原因分析を見ていきます。
- **参照資料**: 論文 §4.3（RQ1）、Table 3-4、contest-report-with-security-agent-v1.md §2.3
- **引用文献**: なし（本研究の結果）
- **図表**: Table 4（戦略別寄与）を図示

---

### Slide 10: 誤検知の最大原因は大規模言語モデルの能力ではなく脅威モデル不整合である
- On-slide (what to show):
  - 棒グラフ: 誤検知原因分布
    - 脅威モデル不整合: 21件 (56.8%) ← 最大、強調
    - 既知/重複: 8件 (21.6%)
    - 分析エラー: 5件 (13.5%)
    - スコープ外: 3件 (8.1%)
  - 具体例の対比:
    - 我々の前提: 「実行層を信頼しない」
    - コンテストルール: 「実行層は信頼コンポーネント」
- Speaker script (what to say):
  37件の誤検知を分析した結果、最大の原因は「脅威モデル不整合」で56.8%を占めました。脅威モデルとは、「誰が攻撃者になりうるか」「どこまでを信頼するか」という前提条件のことです。具体的には、我々のプロンプトでは実行層、つまりトランザクションを処理する部分を「信頼しない」と設定していましたが、コンテストのルールでは「信頼コンポーネント」として扱われていました。この前提条件のズレが21件の誤検知を生みました。重要な洞察は、誤検知の過半数が大規模言語モデルの推論能力の問題ではなく、前提条件の不整合に起因しているという点です。これは、工程として前提を明示化することで改善可能です。
- Transition: しかし、本手法には明確な限界もあります。
- **参照資料**: 論文 §4.4（RQ2）、Table 7、contest-report-with-security-agent-v1.md §6
- **引用文献**: なし（本研究の結果）
- **図表**: Table 7（誤検知原因分布）を図示

---

### Slide 11: V1では高・中重大度を見逃したがV2でチェック可能性を回復した
- On-slide (what to show):
  - 重大度別検出率の表（V1）:
    - 高（High）: 0/5 (0%)
    - 中（Medium）: 0/2 (0%)
    - 低（Low）: 1/8 (12.5%)
  - 見逃し原因の内訳（円グラフまたはバー）:
    - 複雑な状態遷移: 42.9%（3件）
    - 動的境界条件: 28.6%（2件）
    - 外部依存: 14.3%（1件）
    - 仕様ニュアンス: 14.3%（1件）
  - V2での改善を示す矢印:
    - 「プログラムグラフ + 完全カバレッジチェックリストで対応可能」
- Speaker script (what to say):
  V1では、高重大度5件、中重大度2件、計7件の重大な脆弱性をすべて見逃しました。見逃しの原因を分析すると、42.9%が「複雑な状態遷移」、28.6%が「動的境界条件」でした。しかし重要なのは、これらは本手法の根本的な限界ではなく、チェックリストを充実させることで改善可能な課題であるという点です。実際、V2アーキテクチャでは、仕様をプログラムグラフとして形式化し、ノード・パスカバレッジ100%を目指したチェックリストを構築しました。このV2チェックリストを用いて最新のGethコードを監査したところ、V1で見逃していた複雑な状態遷移や動的境界条件に関するチェックも実行可能であることを確認しています。つまり、見逃しの原因はモデル能力ではなく、チェックリストの網羅性の問題であり、仕様の形式化を深めることで対処できます。
- Transition: これらの結果から、手法の得意・不得意と改善の方向性が明確になりました。
- **参照資料**: 論文 §4.5（RQ3）、Table 8-9、contest-report-with-security-agent-v1.md §5、research_notes.md §5.4（V2での再チェック）
- **引用文献**: なし（本研究の結果）
- **図表**: Table 8（重大度別検出率）、Table 9（見逃し原因分布）を図示

---

### Slide 12: V1の課題はV2のチェックリスト充実で改善可能である
- On-slide (what to show):
  - 3列構成:
    - 左列（緑）「V1の強み」:
      - 規範要件（MUST/SHOULD）の直接検証
      - 多実装への横展開（1→N）
      - 証跡付き監査レポート生成
    - 中列（黄）「V1の課題」:
      - 複雑な状態遷移（深い状態到達性）
      - 動的境界条件（実行時決定）
      - 外部依存・仕様の微妙なニュアンス
    - 右列（青）「V2での改善」:
      - プログラムグラフで状態遷移を明示化
      - ノード・パスカバレッジ100%のチェックリスト
      - プロパティ抽出の体系化
  - 矢印: 「課題 → チェックリスト充実で対応可能」
- Speaker script (what to say):
  V1の結果をまとめると、本手法は規範要件の直接検証と、発見の多実装への横展開に強みがあります。仕様から抽出したチェックリストにより、監査を再現可能な工程として固定でき、証跡も残せます。V1では複雑な状態遷移や動的境界条件の検出に課題がありましたが、これらは手法の根本的な限界ではありません。V2では、仕様をプログラムグラフとして形式化し、グラフのノード・パスカバレッジが100%になるようにチェックリストを構築することで、これらの課題に対応しています。実際に最新のGethコードで検証したところ、V1で見逃していたタイプの問題もチェック可能であることを確認しました。つまり、改善の方向性は「別の手法との統合」ではなく「チェックリストの網羅性向上」であり、本フレームワークの拡張として対処可能です。
- Transition: 関連研究との比較で、本手法の位置づけを確認します。
- **参照資料**: research_notes.md §9（Discussion）、§5（V2改善）、論文 §4.6
- **引用文献**: なし（本研究の考察）

---

### Slide 13: 本手法は仕様起点×多実装×脅威モデル形式化で差別化される
- On-slide (what to show):
  - ポジショニングマップ（2軸: 仕様起点 vs コード起点、単一実装 vs 多実装）
  - 比較対象:
    - RFCAudit: 仕様起点、単一実装
    - RepoAudit: コード起点、単一実装（検証器重視）
    - Fluffy/LOKI: コード起点、多実装（差分依存）
    - SpecAudit: 仕様起点、多実装（チェックリスト再利用）
  - 「脅威モデル形式化」を独自要素として強調
- Speaker script (what to say):
  関連研究と比較すると、RFCAuditは仕様起点ですが単一実装を対象としています。RepoAuditはコード起点で検証器による誤検知削減を重視します。FluffyやLOKIは多実装の差分を利用しますが、仕様への言及はありません。SpecAuditは、仕様起点で多実装に対応し、かつ脅威モデルを明示的に形式化する点で差別化されます。特に、誤検知の最大原因が脅威モデル不整合であるという知見に基づき、前提条件を工程として固定することを重視しています。
- Transition: 最後に、本研究の貢献と今後の展望をまとめます。
- **参照資料**: 論文 §2（Related Work）、§2.6（Positioning Summary）、research_notes.md §7
- **引用文献**:
  - Wei et al., "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications" arXiv:2506.00714, 2025 [5]
  - "RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing" arXiv:2501.18160, 2025 [8]
  - Yang et al., "Fluffy" OSDI, 2021 [1]
  - Ma et al., "LOKI" NDSS, 2023 [2]

---

### Slide 14: 仕様チェックリスト化と前提の形式化が監査をスケールさせる
- On-slide (what to show):
  - 3つの貢献（番号付きリスト）:
    1. 横展開チェックが有効発見の76.5%を占めた（13/17件）
    2. 誤検知の56.8%が脅威モデル不整合に起因（21/37件、改善可能）
    3. 高・中重大度未検出の原因は複雑状態遷移・動的境界（0/7件、限界）
  - 持ち帰りメッセージ: 「監査のボトルネックはモデルの賢さだけでなく、前提・境界・規範要件の固定にある」
  - 今後の方向: モデル検査との統合、プロパティベーステスト、仕様の形式化
- Speaker script (what to say):
  本研究の貢献をまとめます。第一に、多実装環境において、横展開チェックが有効発見の76.5%を占め、チェックリスト再利用による横展開の有効性を示しました。第二に、誤検知の56.8%が脅威モデル不整合に起因しており、大規模言語モデルの能力向上だけでなく、前提条件の形式化が重要であることを示しました。第三に、高・中重大度脆弱性の未検出という限界を正直に報告し、その原因を分析しました。監査のボトルネックは「モデルを賢くする」だけでなく、「前提・境界・規範要件を工程として固定する」ことにあると考えています。今後は、モデル検査やシンボリック実行との統合、脅威モデルの形式化の実証評価を進めていく予定です。
- Transition: 以上で発表を終わります。ご質問をお待ちしております。
- **参照資料**: 論文 §5（Conclusion）、research_notes.md §10
- **引用文献**: なし（まとめスライド）

---

### Slide 15: ご清聴ありがとうございました
- On-slide (what to show):
  - タイトル: 「ご清聴ありがとうございました」
  - 連絡先・所属
  - QRコード（論文/コードへのリンク、任意）
  - 主要数値の再掲（小さく）:
    - 横展開チェック: 76.5%
    - 誤検知・脅威モデル: 56.8%
    - 高・中重大度: 0%
- Speaker script (what to say):
  ご清聴ありがとうございました。SpecAuditは、仕様チェックリストを用いて多実装の整合性を監査するフレームワークです。実運用環境での評価により、横展開戦略の有効性と、脅威モデル形式化の重要性を示しました。ご質問やご意見をお待ちしております。
- Transition: （Q&Aへ）
- **参照資料**: なし
- **引用文献**: なし

---

## Backup Slides（6枚）

### Backup 1: 具体的な発見事例 - Nimbus カストディローテーション DoS
- On-slide:
  - 発見のフロー図:
    1. 仕様: 「カストディグループ数は NUMBER_OF_CUSTODY_GROUPS (128) を超えてはならない」
       ※カストディグループ: データ可用性サンプリングで各ノードが担当するデータ群
    2. マッピング: peerdas_helpers.nim
    3. 逸脱: ループ条件で検証なし（`while custody_groups.len < custody_group_count`）
  - コード断片（該当箇所をハイライト）
  - 結果: 低重大度として認定
- Speaker script:
  唯一の低重大度発見の具体例です。仕様から「カストディグループ数は128を超えてはならない」という要件を抽出しました。カストディグループとは、データ可用性サンプリングという技術で各ノードが担当するデータの集まりのことです。Nimbusの該当コードにマッピングした結果、この上限チェックがループ条件で行われておらず、悪意あるピアが過大な値を送ることでサービス拒否攻撃が可能でした。これは仕様駆動監査の成功例です。
- **参照資料**: contest-report-with-security-agent-v1.md §4.1、issue-15
- **引用文献**: なし

### Backup 2: V2改善 - プログラムグラフによる仕様形式化と完全カバレッジ
- On-slide:
  - V1→V2の改善ポイント図（4フェーズ）:
    1. **SPEC（プログラムグラフ）**: 仕様を状態・遷移・ガード条件のグラフとして形式化
       - 深い状態遷移も明示的にノード化
       - 成果物: 126KB（状態、定数、不変条件、手続きを網羅）
    2. **TRUSTMODEL**: アクターと信頼境界を形式化
       - 8アクター、12境界エッジ
       - 信頼レベル: 信頼 / 半信頼 / 非信頼
    3. **CHECKLIST**: グラフのノード・パスカバレッジ100%を目標に構築
       - 境界チェックリスト: 40項目
       - プロパティチェックリスト: 180項目（9ファイル）
    4. **AUDITMAP**: ガード検証・到達可能性・暗号チェックを実行
  - V1の見逃し原因とV2での対策の対応表:
    | V1の見逃し原因 | V2での対策 |
    |:---------------|:-----------|
    | 複雑な状態遷移 | プログラムグラフで深い遷移を明示化 |
    | 動的境界条件 | ガード条件をノードとして抽出 |
    | 仕様ニュアンス | プロパティ抽出を体系化 |
    | 脅威モデル不整合 | TRUSTMODELを独立フェーズに |
- Speaker script:
  V1で高・中重大度を見逃した原因を分析し、V2では4つのフェーズで改善しました。最大の改善点は、仕様をプログラムグラフとして形式化したことです。従来は自然言語の規範要件を抽出していましたが、V2では状態、遷移、ガード条件をグラフ構造として記述します。これにより、V1で見逃した「複雑な状態遷移」、例えばフォーク境界での長い状態変化も、グラフのパスとして明示的に表現できます。次に、このグラフのノードとパスのカバレッジが100%になるようにチェックリストを構築します。境界チェックリスト40項目、プロパティチェックリスト180項目を生成し、チェックすべきコードを見逃さないようにしました。また、脅威モデルを独立フェーズとして形式化し、「実行層は信頼するか」といった前提を事前に固定することで、V1で発生した56.8%の脅威モデル不整合を構造的に削減します。V2は設計提案であり、見逃した高・中重大度に対してチェック可能性が回復したことを確認していますが、大規模な実証評価は今後の課題です。
- **参照資料**: research_notes.md §3.2（V2の4フェーズ）、§5.1（V2の狙い）、§5.2（V2アーティファクト）、§5.4（V1見逃しの再チェック）
- **引用文献**: なし

### Backup 3: 他の参加者はどのように高・中重大度を発見したか
- On-slide:
  - 高・中重大度の発見手法詳細（表）:
    | ID | 重大度 | 脆弱性 | 発見手法（実際の報告から推定） |
    |:---|:-------|:-------|:-------------------------------|
    | #40 | 高 | プロポーザルックアヘッド未考慮 | **仕様精読** + 有効残高変更のPoCテスト |
    | #190 | 高 | Prysm包含証明キャッシュ不備 | **仕様・コード比較**（キャッシュキーに`kzg_commitments`未含） |
    | #203 | 高 | c-kzg弱いフィアット・シャミア | **暗号学的分析**（チャレンジ計算の問題点特定） |
    | #176 | 高 | 不正ブロブTxでブロック生成停止 | **入力検証分析**（N>Mのハッシュ/ブロブ数不一致） |
    | #210 | 高 | ブロブハッシュ不一致許容 | **検証ギャップ分析**（等価チェック欠落を発見） |
    | #15 | 中 | Nimbus過大CGCによるDoS | **レースコンディション分析**（メタデータ呼出間） |
    | #216 | 中 | Nimbus古いメタデータ使用 | **フォーク境界の状態遷移分析** |
  - 発見手法の分類（円グラフ）:
    - 仕様精読・比較: 2件 (#40, #190)
    - 入力検証・境界分析: 2件 (#176, #210)
    - 暗号学的分析: 1件 (#203)
    - 状態遷移分析: 2件 (#15, #216)
  - キーメッセージ: 「深いドメイン知識 + PoCによる実証」が共通点
- Speaker script:
  コンテストのレポート内容から、高・中重大度を発見した参加者が実際にどのような手法を用いたかを分析しました。#40のプロポーザルックアヘッド問題は、仕様書の「proposer lookahead」条項を精読し、有効残高を変更するPoCテストで実証しています。#190のPrysmキャッシュ問題は、仕様とコードを詳細に比較し、キャッシュキーに`kzg_commitments`が含まれていないという設計上の見落としを発見しています。#203の暗号脆弱性は、c-kzg-4844ライブラリのフィアット・シャミア変換におけるチャレンジ計算を暗号学的に分析し、弱点を特定しています。#176と#210は入力検証の網羅的分析で、それぞれブロブハッシュ数とブロブ数の不一致、ハッシュと実データの不一致を許容するギャップを発見しています。#15と#216は状態遷移の詳細分析で、メタデータ更新のレースコンディションとフォーク境界での状態管理問題を発見しています。共通するのは、表面的なコードレビューではなく、深いドメイン知識に基づく分析と、PoCによる実証を組み合わせている点です。
- **参照資料**: sherlock_contest_1140_issues_1766639267091.csv（各Issueのdescriptionフィールド）
- **引用文献**: なし

### Backup 4: 見逃した高・中重大度脆弱性の詳細と発見に必要だった手法
- On-slide:
  - 7件の高・中重大度脆弱性の詳細表:
    | ID | 重大度 | 脆弱性内容 | 見逃し原因 | 発見に必要だった手法 |
    |:---|:-------|:-----------|:-----------|:---------------------|
    | #40 | 高 | プロポーザ計算でルックアヘッド未考慮 | 仕様ニュアンス | 仕様の「proposer lookahead」条項の精読 |
    | #190 | 高 | Prysmが包含証明検証結果を誤キャッシュ | 複雑状態遷移 | クライアント固有のキャッシュ実装分析 |
    | #203 | 高 | c-kzg-4844の弱いフィアット・シャミア変換 | 外部依存 | 暗号ライブラリの専門監査 |
    | #176 | 高 | 不正ブロブTxでNethermindブロック生成停止 | 動的境界 | ファジング（異常入力テスト） |
    | #210 | 高 | Nethermindがブロブハッシュと実データの不一致を許容 | 動的境界 | 入力検証の網羅テスト |
    | #15 | 中 | Nimbusで過大なカストディグループ数によるDoS | 複雑状態遷移 | メタデータ更新の状態遷移分析 |
    | #216 | 中 | NimbusがFuluフォーク後に古いメタデータを使用 | 複雑状態遷移 | フォーク境界の状態遷移テスト |
  - 色分け凡例: 仕様精読、状態遷移分析、暗号監査、ファジング
- Speaker script:
  見逃した7件を詳細に分析すると、発見に必要だった手法が見えてきます。#40はプロポーザ、つまりブロック提案者の計算において、仕様に記載された「proposer lookahead」という条件を見落としていました。これは仕様の精読で発見可能でした。#190はPrysmクライアント固有のキャッシュ実装で、検証結果を誤ってキャッシュするバグです。これはクライアント固有の深いコード分析が必要でした。#203は外部の暗号ライブラリc-kzg-4844の問題で、フィアット・シャミア変換という暗号技法の実装が弱かった。これは暗号学の専門知識と依存関係スキャンが必要でした。#176と#210はNethermindの実行層で、不正な入力データの処理に関する問題です。これらはファジングや異常入力テストで発見できた可能性があります。#15と#216はNimbusの状態遷移、特にフォーク境界での挙動に関する問題で、状態遷移の体系的分析が必要でした。
- **参照資料**: contest-report-with-security-agent-v1.md §5.2、sherlock_contest_1140_statistics.md、research_notes.md §4.4
- **引用文献**: なし

### Backup 5: 我々の手法と高重大度発見手法の比較
- On-slide:
  - 2列比較図:
    - 左列「我々の手法（SpecAudit）」:
      - 強み: 仕様チェックリスト駆動、横展開（1→N）、再現性
      - 成果: 17件有効（うち低1件、情報提供16件）
      - 限界: 静的分析中心、外部依存未対応、動的境界未対応
    - 右列「高重大度発見者の手法（推定）」:
      - 強み: 専門特化（暗号学、状態遷移）、深掘り分析
      - 成果: 高5件、中2件を発見
      - 限界: スケールしにくい、属人的
  - 補完関係を示す矢印: 「両者の組み合わせが理想」
- Speaker script:
  我々の手法と高重大度発見者の手法を比較すると、明確な補完関係が見えます。SpecAuditは仕様チェックリストを用いた横展開に強く、多数の有効発見を効率的に生み出しました。一方、高重大度を発見した参加者は、暗号学的実装や状態遷移といった特定領域に深く特化していたと推測されます。SpecAuditの限界は、外部依存のライブラリ監査や動的なファジングが含まれていなかった点です。理想的には、SpecAuditによる広範な仕様準拠チェックと、専門特化型の深掘り分析を組み合わせることで、カバレッジと深度の両立が可能になると考えています。今後の改善として、暗号ライブラリの依存関係スキャンや、プロパティベースのファジングをパイプラインに統合することを検討しています。
- **参照資料**: contest-report-with-security-agent-v1.md §5, §8、research_notes.md §9
- **引用文献**: なし

### Backup 6: 評価環境の詳細 - Fusakaコンテストの重大度定義
- On-slide:
  - 重大度閾値の表:
    - 致命的（Critical）: ネットワークの50%超に影響（スラッシュ、停止等）
    - 高（High）: 33%超に影響
    - 中（Medium）: 5%超に影響
    - 低（Low）: 0.01%超に影響
    - 情報提供（Informational）: クライアント側が修正価値を認めた場合のみ有効
  - 賞金プール: $2,000,000（うち情報提供プール: $25,000）
  - スコアリング: Critical 30点、High 10点、Medium 5点、Low 2点
  - 「低・情報提供でも運用上の価値がある」というメッセージ
- Speaker script:
  Fusakaコンテストの重大度定義は非常に厳格で、高重大度はネットワークの33%以上に影響を与える脆弱性に限定されます。これはEthereumネットワーク全体の約3分の1のノードに影響するという意味で、極めて高いハードルです。賞金プールは総額200万ドルで、高重大度以上が発見されると50万ドルのプールが解放される仕組みでした。このため、低重大度や情報提供レベルでも、実運用における事故回避や仕様準拠性の担保として十分な価値があります。我々の17件の有効発見のうち16件が情報提供レベルでしたが、これらはすべてクライアント開発チームが修正価値を認め、実際に修正が行われたものです。
- **参照資料**: research_notes.md §4.5.1（Severity定義）、§4.5.1b（Prize Distribution）、sherlock_contest_1140_statistics.md
- **引用文献**: なし

---

## 発表時間配分（目安）

| スライド | 内容 | 目安時間 |
|:--------|:-----|:--------|
| 1 | タイトル | 30秒 |
| 2 | 背景：仕様と実装の整合性 | 50秒 |
| 3 | 問題：共通誤解 | 50秒 |
| 4 | ギャップ：差分テストの限界 | 60秒 |
| 5 | キーアイデア：仕様チェックリスト | 50秒 |
| 6 | 提案：SpecAudit概要 | 50秒 |
| 7 | 戦略B：横展開チェック | 60秒 |
| 8 | 評価環境：Fusaka | 50秒 |
| 9 | 結果1：戦略別寄与 | 60秒 |
| 10 | 結果2：誤検知原因分析 | 60秒 |
| 11 | 結果3：限界分析 | 60秒 |
| 12 | 議論：得意・苦手 | 50秒 |
| 13 | 関連研究との位置づけ | 50秒 |
| 14 | 結論・貢献 | 60秒 |
| 15 | Thank you | 20秒 |
| **合計** | | **約14分** |

---

## 引用文献一覧（発表で言及するもの）

[1] S. Yang et al., "Finding Consensus Bugs in Ethereum via Multi-Transaction Differential Fuzzing (Fluffy)," OSDI, 2021.

[2] F. Ma et al., "LOKI: State-Aware Fuzzing Framework for the Implementation of Blockchain Consensus Protocols," NDSS, 2023.

[3] I. Kim et al., "Fork State-Aware Differential Fuzzing for Blockchain Consensus Implementations (FORKY)," ICSE, 2025.

[4] J. C. Knight and N. G. Leveson, "An Experimental Evaluation of the Assumption of Independence in Multiversion Programming," IEEE TSE, 1986.

[5] Z. Wei et al., "RFCAudit: AI Agent for Auditing Protocol Implementations Against RFC Specifications," arXiv:2506.00714, 2025.

[6] K. Liu et al., "Synthesizing Precise Protocol Specs from Natural Language for Effective Test Generation (AUTOSPEC)," arXiv:2511.17977, 2025.

[8] "RepoAudit: An Autonomous LLM-Agent for Repository-Level Code Auditing," arXiv:2501.18160, 2025.

---

## スライドデザインガイドライン

- **フォント**: BIZ UDPMincho（日本語）
- **背景**: 白
- **文字・図**: 黒基調（アクセントカラーは赤・緑を控えめに）
- **タイトル**: 各スライドは「主張の文章」をタイトルに（名詞句禁止）
- **本文**: 箇条書きは最小限、視覚的証拠（図・表・数値）中心
- **1スライド = 1メッセージ**: 要素は最大3つ
- **タイトル/Thank youスライド**: coverレイアウト
- **用語**: 英語は固有名詞を除き日本語/カタカナに統一、Ethereum専門用語は初出で説明を付記
- 参考文献は各ページの左下に記述